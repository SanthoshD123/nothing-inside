<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LLM Journey by Armand Ruiz</title>
    <style>
      body {
        font-family: "Arial", sans-serif;
        line-height: 1.6;
        color: #333;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f4f4f4;
      }
      header {
        background-color: #2c3e50;
        color: #ecf0f1;
        text-align: center;
        padding: 1em;
        margin-bottom: 20px;
      }
      h1 {
        margin: 0;
      }
      .author {
        font-style: italic;
        margin-top: 10px;
      }
      
      .day-buttons {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        margin-bottom: 20px;
        justify-content: center;
      }

      .day-button {
        background-color: #3498db;
        color: white;
        border: none;
        padding: 12px 18px;
        cursor: pointer;
        transition: background-color 0.3s, transform 0.1s;
        border-radius: 5px;
        font-size: 16px;
        font-weight: bold;
        min-width: 80px;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
      }

      .day-button:hover {
        background-color: #2980b9;
        transform: translateY(-2px);
      }

      .day-button:focus {
        outline: 3px solid #f39c12;
        outline-offset: 2px;
      }

      .day-button:active {
        transform: translateY(1px);
      }

      @media (max-width: 600px) {
        .day-button {
          padding: 10px 15px;
          font-size: 14px;
          min-width: 70px;
        }
      }
      .content {
        background-color: white;
        padding: 20px;
        border-radius: 5px;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      }
      .content > div {
        display: none;
      }
      .content > div.active {
        display: block;
      }
      h2 {
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 10px;
      }
      p {
        margin-bottom: 15px;
      }
      ul,
      ol {
        padding-left: 20px;
        margin-bottom: 15px;
      }
      footer {
  background-color: #f2f2f2;
  padding: 20px 0;
  text-align: center;
  font-family: Arial, sans-serif;
  font-size: 14px;
  color: #555;
}

.footer-content {
  max-width: 1200px;
  margin: 0 auto;
}

.your-info {
  text-align: center;
}

.your-name {
  font-weight: bold;
  margin-bottom: 5px;
}

.social-icons {
  margin-top: 5px;
}

.social-icons a {
  display: inline-block;
  margin-right: 10px;
}

.social-icons img {
  width: 30px; /* Adjust as needed */
  height: auto;
}

    </style>
  </head>
  <body>
    <header>
      <h1>GEN AI Journey</h1>
      <div class="author">
        By Armand Ruiz, VP of Product - AI Platform @IBM
      </div>
    </header>
    
    

    <div class="day-buttons">
      <button class="day-button" data-day="1">Day 1</button>
      <button class="day-button" data-day="2">Day 2</button>
      <button class="day-button" data-day="3">Day 3</button>
      <button class="day-button" data-day="4">Day 4</button>
      <button class="day-button" data-day="5">Day 5</button>
      <button class="day-button" data-day="6">Day 6</button>
      <button class="day-button" data-day="7">Day 7</button>
      <button class="day-button" data-day="8">Day 8</button>
      <button class="day-button" data-day="9">Day 9</button>
      <button class="day-button" data-day="10">Day 10</button>
      <button class="day-button" data-day="11">Day 11</button>
      <button class="day-button" data-day="12">Day 12</button>
      <button class="day-button" data-day="13">Day 13</button>
      <button class="day-button" data-day="14">Day 14</button>
      <button class="day-button" data-day="15">Day 15</button>
      <!-- Add buttons for days 7-15 here -->
    </div>

    <div class="content">
      <div id="day1">
        <h2>Day 1 - Introduction to Generative AI</h2>
        <p>Welcome to Day 1 of our Generative AI journey!</p>
        <p>
          Today, I'm uncovering what Generative AI is and why it's a
          game-changer in the business world.
        </p>
        <p>
          Imagine AI not just analyzing data but creating new, innovative
          content – that's Generative AI!
        </p>
        <p>
          Ok let's start with the basics, but don't worry, we will get into more
          advanced concepts as we go.
        </p>

        <h3>Definition of terms</h3>
        <ul>
          <li>
            <strong>Artificial Intelligence (AI):</strong> AI is the broad field
            of computer science focused on creating machines capable of
            performing tasks that typically require human intelligence.
          </li>
          <li>
            <strong>Machine Learning (ML):</strong> ML is a subset of AI
            involving algorithms and statistical models that enable computers to
            improve their performance on a task through experience.
          </li>
          <li>
            <strong>Deep Learning:</strong> Deep Learning is a subset of ML
            based on artificial neural networks, where algorithms learn from
            large amounts of data to identify patterns and make decisions.
          </li>
          <li>
            <strong>Generative AI:</strong> Generative AI refers to AI
            technologies that can generate new content, ideas, or data that are
            coherent and plausible, often resembling human-generated outputs.
          </li>
        </ul>

        <h3>What powers Generative AI</h3>
        <p>
          Foundation models are large-scale artificial intelligence models that
          have been trained on vast amounts of data. These models are highly
          versatile and can be adapted to a wide range of tasks and
          applications.
        </p>
        <p>
          Generative AI is one of the applications of foundation models. It
          involves using these models to create new content, such as text,
          images, or music. The foundation model serves as the underlying
          structure that understands and processes information, enabling the
          generative AI to produce new, coherent, and relevant outputs.
        </p>
        <p>
          In simple terms, foundation models are like the core engine, and
          generative AI is one of the many things that this engine can power.
        </p>

        <h3>What makes Foundation Models so powerful?</h3>
        <ul>
          <li>
            <strong>Pretrained:</strong> The model has already been trained on a
            vast dataset before being fine-tuned or applied to specific tasks.
          </li>
          <li>
            <strong>Generalized:</strong> The model is capable of performing
            well across a wide range of tasks, not just the ones it was
            specifically trained for.
          </li>
          <li>
            <strong>Adaptable:</strong> The model can be easily modified or
            fine-tuned to suit particular needs or tasks.
          </li>
          <li>
            <strong>Large:</strong> The model is built with a substantial
            architecture and trained on extensive data, giving it a broad
            understanding and capability.
          </li>
          <li>
            <strong>Self-supervised:</strong> The model primarily learns by
            analyzing and making sense of unlabeled data, without explicit
            guidance on what to learn.
          </li>
        </ul>

        <h3>What are Large Language Models?</h3>
        <p>
          Large Language Models (LLMs) are a type of foundation model
          specifically designed to understand and generate text. They're trained
          on huge amounts of text, which makes them good at a wide range of
          language tasks. LLMs are part of the broader category of foundation
          models, meaning they're versatile and can be adapted for different
          uses involving language.
        </p>
        <p>
          LLMs like GPT take, as input, an entire sequence of words, and
          predicts which word is most likely to come next. They perform that
          prediction of the next word in a sequence by analyzing patterns in
          vast amounts of text data.
        </p>
        <p>
          There's a big debate that LLMs do more than predict the next word;
          they compress a "world-model" within their complex networks and
          weights. This is an area of active debate within the AI community.
        </p>

        <h3>Two important concepts to understand in LLMs are:</h3>
        <ul>
          <li>
            <strong>Weights:</strong> Numerical values within a machine learning
            model that are adjusted during training to influence the model's
            output in response to input data.
          </li>
          <li>
            <strong>Parameters:</strong> The broader set of configurable
            elements in a model, including weights, that determine its behavior
            and performance.
          </li>
          <li>
            <strong>Tokenization:</strong> The process of converting text into
            smaller units (tokens), such as words or subwords, which are used as
            the input for LLMs to understand and generate language.
          </li>
        </ul>
      </div>

      <div id="day2">
        <h2>Day 2 - Types of Generative AI Models</h2>
        <p>
          Welcome to Day 2 of our Generative AI journey! Today, we're diving
          into the different types of Generative AI models, each with its unique
          capabilities and applications.
        </p>

        <p>To keep it simple, I summarized this in four types:</p>
        <ol>
          <li>
            <strong>Generative Adversarial Networks (GANs):</strong> These
            models are game-changers in image generation, creating everything
            from art to realistic photos.
          </li>
          <li>
            <strong>Variational Autoencoders (VAEs):</strong> VAEs are great for
            tasks that involve compressing and generating high-quality images,
            offering applications in style transfer and more.
          </li>
          <li>
            <strong>Transformer Models:</strong> Known for their prowess in
            text, transformer models like GPT are revolutionizing text
            generation, translation, and automated writing.
          </li>
          <li>
            <strong>Restricted Boltzmann Machines (RBMs):</strong> RBMs excel in
            understanding complex data patterns, aiding in tasks like feature
            learning and topic modeling.
          </li>
        </ol>

        <p>
          But to simplify it even further, let's talk about Generative Language
          Models and Generative Image Models:
        </p>
        <ul>
          <li>
            Generative language models learn about patterns in language through
            training data. Then, given some text, they predict what comes next.
          </li>
          <li>
            Generative image models produce new images using techniques like
            diffusion. Then, given a prompt or related imagery, they transform
            random noise into images or generate images from prompts.
          </li>
        </ul>

        <p>
          There's a research paper that changed everything, called 'Attention is
          All You Need'.
        </p>
        <p>This paper introduced:</p>
        <ol>
          <li>
            <strong>Transformers:</strong> The paper presented the transformer
            model, moving away from traditional Deep Learning methodologies that
            were quite limiting such as Recurrent Neural Network (RNNs) and
            Convolutional Neural Network (CNNs) in NLP.
          </li>
          <li>
            <strong>Self-Attention Mechanism:</strong> Transformers use
            self-attention to efficiently process different parts of input data.
          </li>
          <li>
            <strong>Improved Parallelization:</strong> Transformers enable more
            efficient training through better parallelization compared to RNNs.
          </li>
          <li>
            <strong>Enhanced NLP Performance:</strong> They significantly
            outperform previous models in tasks like machine translation and
            text summarization.
          </li>
          <li>
            <strong>Basis for Advanced Models:</strong> The transformer
            architecture underpins major NLP models like BERT and GPT, enhancing
            language processing capabilities.
          </li>
        </ol>

        <p>
          While I've focused on text and image generation, it's exciting to note
          that similar principles are being applied to audio and video
          generation, which is likely going to start exploding this 2024 and
          beyond. AI is now creating music, sound effects, and even generating
          or altering video content. The potential in these areas is vast and
          still unfolding.
        </p>
      </div>

      <div id="day3">
        <h2>
          Day 3 - Traditional ML vs Generative AI or Discriminative vs
          Generative Models
        </h2>
        <p>
          Welcome to Day 3! Today, we're diving deeper into the AI landscape by
          contrasting Traditional Machine Learning (ML), focusing on
          discriminative models, against Generative AI, which revolves around
          generative models.
        </p>

        <p>
          To start, let's understand the difference between with a simple
          example:
        </p>

        <h3>Traditional Machine Learning</h3>
        <p>
          Discriminative models in Traditional ML are designed to classify or
          predict outcomes based on input data. They focus on drawing boundaries
          between different categories and making decisions.
        </p>
        <p>
          <strong>Application Examples:</strong> Predictive analytics in
          business forecasting, spam filters in email systems, and
          recommendation systems in streaming services.
        </p>
        <p><strong>Key Characteristics:</strong></p>
        <ul>
          <li>
            <strong>Supervised Learning:</strong> Often relies on labeled data
            sets to train models. Labeling data is very expensive and
            time-consuming.
          </li>
          <li>
            <strong>Predictive Accuracy:</strong> Emphasizes the accuracy of
            predictions based on known data.
          </li>
          <li>
            <strong>Analytical Approach:</strong> Aims to understand data and
            draw conclusions.
          </li>
        </ul>

        <h3>Generative AI</h3>
        <p>
          In contrast, Generative AI doesn't just analyze data; it creates new
          data that didn't exist before. It's about innovation and creation,
          generating new content that is similar to but distinct from the
          training data.
        </p>
        <p>
          <strong>Application Examples:</strong> Creating new images or artwork,
          generating realistic human-like text, or composing music.
        </p>
        <p><strong>Key Characteristics:</strong></p>
        <ul>
          <li>
            <strong>Creative Output:</strong> Produces new content, extending
            beyond analysis.
          </li>
          <li>
            <strong>Model Types:</strong> Uses models like GANs (Generative
            Adversarial Networks) and VAEs (Variational Autoencoders) for
            content generation.
          </li>
          <li>
            <strong>Innovation Focused:</strong> Pushes the boundaries of what
            machines can create.
          </li>
        </ul>

        <h3>The Role of Discriminative vs Generative in AI</h3>
        <p>
          The distinction between discriminative and generative models is vital.
          Discriminative models excel in classification and prediction tasks,
          making them suitable for analytical applications. In contrast,
          generative models are unparalleled in their ability to create and
          innovate, making them ideal for tasks requiring new content
          generation.
        </p>
        <p>
          Understanding whether your business needs to analyze and classify
          existing data or generate new, unseen content will guide you in
          choosing the right AI approach.
        </p>
      </div>

      <!-- Add divs for days 4-6 here, following the same structure -->
      <div id="day4">
        <h2>Welcome to Day 4 - Demystifying GPUs in AI</h2>
        <p>
          Today, we're focusing on GPUs - the driving force behind the AI
          revolution, especially in training and inference tasks.
        </p>

        <h3>What are GPUs?</h3>
        <p>
          GPUs, or Graphics Processing Units, were initially designed for
          rendering graphics and video tasks. Remember the excitement of
          upgrading your PC with a new GPU for better gaming? That same
          technology has become pivotal in AI, thanks to its architecture and
          parallel processing capabilities.
        </p>

        <h3>Why are GPUs Crucial for AI?</h3>
        <ul>
          <li>
            <strong>GPU Architecture:</strong> GPUs have thousands of small
            cores (organized into Streaming Multiprocessors) designed for
            parallel computing. This setup is perfect for AI workloads, which
            often require simultaneous processing of large data sets.
          </li>
          <li>
            <strong>Parallel Processing Power:</strong> GPUs excel at performing
            multiple calculations at once, making them ideal for handling the
            complex mathematical operations needed in AI.
          </li>
          <li>
            <strong>Speed and Efficiency:</strong> With rapid thread switching
            and high memory latency tolerance, GPUs significantly reduce the
            time needed for training neural networks, like GPT-3, which requires
            300 zettaflops of computing power.
          </li>
          <li>
            <strong>AI Framework Support:</strong> Manufacturers like Nvidia,
            AMD, and Intel have optimized GPUs for AI frameworks such as
            TensorFlow and PyTorch.
          </li>
        </ul>

        <h3>The Rise of AI Supercomputers</h3>
        <p>
          AI research has skyrocketed with the advent of AI supercomputers,
          clusters of GPUs working together. These supercomputers, like Summit,
          Sierra, and Fugaku, are pushing the boundaries in fields like
          scientific research and climate modeling.
        </p>

        <!-- Add content for Day 4 here -->

        <h3>Selecting the Right GPU</h3>
        <p>
          Choosing the appropriate GPU involves understanding your needs -
          whether it's for AI training, inference, or both, and balancing
          factors like budget, performance, compatibility, and scalability.
        </p>

        <h3>The Future of GPUs in AI</h3>
        <p>
          We're witnessing a 1000X increase in single-chip GPU performance over
          the last decade. The future holds more specialized AI chips, quantum
          computing advancements, and edge AI integrations, further transforming
          the AI landscape.
        </p>

        <p>
          In conclusion, GPUs have transitioned from enhancing our gaming
          experiences to becoming the backbone of AI, fueling advancements in
          machine learning and beyond. Their role in accelerating AI workloads
          is indisputable and will continue to shape the future of technology.
        </p>
      </div>

      <div id="day5">
        <h2>Day 5 - What it Takes to Train a Foundation Model</h2>
        <p>
          Welcome to Day 5 of our AI journey! Today, we'll explore the critical
          aspects of training foundation models and why it's a decision that
          requires careful consideration.
        </p>

        <h3>Control Over the Model</h3>
        <ul>
          <li>
            <strong>Tailored Approach:</strong> When you train your model, you
            have control over data and parameters, allowing customization to
            specific styles or domains. This ensures alignment with your
            business needs.
          </li>
          <li>
            <strong>Improved Performance:</strong> Foundation models trained on
            large, diverse datasets can outperform pre-trained models,
            especially if your dataset is domain-specific.
          </li>
          <li>
            <strong>Customization:</strong> Building your own model lets you
            modify aspects like tokenizer, vocabulary size, or architecture,
            crucial for business strategies.
          </li>
        </ul>

        <h3>Challenges of Training from Scratch</h3>
        <ul>
          <li>
            <strong>Data Collection:</strong> Amassing a large, relevant dataset
            is crucial. Consider datasets like The Pile, an extensive, diverse
            language modeling dataset.
          </li>
          <li>
            <strong>Compute Resources:</strong> Significant computational power
            (e.g., AI supercomputers with Nvidia A100 and H100 GPUs) is
            necessary.
          </li>
          <li>
            <strong>Expertise:</strong> Specialized knowledge in AI and ML is
            essential due to model complexity.
          </li>
        </ul>

        <h3>Training Steps</h3>
        <ol>
          <li>
            Dataset Collection: Gather a large, diverse dataset relevant to your
            tasks.
          </li>
          <li>
            Preparation and Tokenization: Clean and format data, breaking it
            down into tokens.
          </li>
          <li>
            Configure Training: Set hyperparameters, choose architecture, and
            allocate resources.
          </li>
          <li>Training: Train your model using deep learning algorithms.</li>
          <li>Evaluation: Test model performance on a separate dataset.</li>
          <li>
            Deployment: Once satisfied, deploy the model for practical use.
          </li>
        </ol>

        <h3>Cost Considerations</h3>
        <p>
          Training a foundation model can range from tens of thousands to
          millions of dollars, depending on model size, data volume, and
          computational resources.
        </p>

        <h3>Recommendation for Businesses</h3>
        <ul>
          <li>
            <strong>Customize a Pre-Trained Model:</strong> Start with a
            pre-trained model and customize it using techniques like Parameter
            Efficient Fine Tuning (PEFT) to save time and resources.
          </li>
          <li>
            <strong>Consider Needs and Resources:</strong> Evaluate your
            specific needs and available resources to decide between purchasing,
            training, or customizing a model.
          </li>
        </ul>

        <p>
          Customizing foundation models offers cost savings, faster results, and
          better performance compared to training from scratch. While
          resource-intensive, it provides unparalleled control and is essential
          for businesses seeking a technological edge in AI.
        </p>
      </div>

      <div id="day6">
        <h2>Day 6 - How to Customize Foundation Models</h2>
        <p>
          Today, on Day 6 of our AI journey, let's unlock the secrets of
          customizing foundation models to suit your specific needs.
          Understanding when and how to tune these models is crucial for optimal
          performance.
        </p>

        <h3>Deciding When to Tune Your Model</h3>
        <p>
          <strong>Starting Point:</strong> Begin with prompt engineering using
          the largest suitable Language Model (LLM) for your task to gauge if
          LLMs can handle it. Experiment with various prompt formats and
          examples.
        </p>

        <h4>Prompting Techniques:</h4>
        <ul>
          <li>
            <strong>Zero-Shot Prompting:</strong> Efficiency with No Extra Data.
            Provide a natural language prompt to generate desired outputs
            without additional training data.
          </li>
          <li>
            <strong>One-Shot Prompting:</strong> A Single Example to Guide.
            Introduce one example along with your prompt to demonstrate the
            desired outcome.
          </li>
          <li>
            <strong>Few-Shot Prompting:</strong> Leveraging a Few Examples.
            Provide 2-3 examples to establish the pattern or style for the model
            to replicate.
          </li>
        </ul>

        <h3>Data-Driven Tuning for Deeper Customization</h3>
        <p>
          <strong>Fine-Tuning:</strong> Adjust model weights on a specific
          dataset to cater to your unique objectives, such as customizing tone
          or addressing complex prompts.
        </p>

        <p>
          <strong>Parameter-Efficient Fine-Tuning (PEFT):</strong> Delta tuning
          updates only a small subset of parameters, offering a faster,
          cost-effective alternative to traditional fine-tuning.
        </p>

        <h4>PEFT Techniques:</h4>
        <ul>
          <li>
            <strong>Prefix Tuning:</strong> Attach vectors with free parameters
            to input embeddings, training them while keeping the LLM frozen.
          </li>
          <li>
            <strong>Prompt Tuning:</strong> A simpler variant of prefix tuning,
            adding a vector only at the input layer.
          </li>
          <li>
            <strong>P-Tuning:</strong> Automate prompt optimization using an
            LSTM model.
          </li>
          <li>
            <strong>LoRA:</strong> Low-Rank Adaptation adds update matrices to
            existing weights, training these new weights.
          </li>
        </ul>

        <h4>Choosing the Right Technique:</h4>
        <p>
          <strong>Goal-Oriented Approach:</strong> Select the customization
          method based on your specific goals and the available data. Zero-shot
          and few-shot prompting work well with minimal data, while data-driven
          tuning is ideal for more complex, data-rich tasks.
        </p>

        <p>
          Customizing foundation models can significantly enhance their
          performance on specific tasks, aligning them with your business
          objectives.
        </p>
      </div>

      <div id="day7">
        <h2>Day 7 - The Most Popular LLMs Available</h2>
        <p>
          Let's explore the world of Large Language Models (LLMs) by
          understanding the key differences between open-source and proprietary
          models.
        </p>

        <h3>Open Source LLMs:</h3>
        <p>
          These models are freely available for use, modification, and
          distribution, promoting community-driven development and innovation.
        </p>
        <h4>Examples of Open Source LLMs:</h4>
        <ul>
          <li>
            <strong>GPT-Neo/GPT-J:</strong> Developed by EleutherAI, these
            models offer similar capabilities to OpenAI's GPT models.
          </li>
          <li>
            <strong>BERT:</strong> Developed by Google, BERT excels in
            understanding context in natural language.
          </li>
        </ul>

        <h3>Closed Source LLMs:</h3>
        <p>
          These models are developed and maintained by private entities, often
          requiring licenses or subscriptions for access.
        </p>
        <h4>Examples of Closed Source LLMs:</h4>
        <ul>
          <li>
            <strong>OpenAI's GPT-3/GPT-4:</strong> Known for advanced
            capabilities, accessible through APIs with usage costs.
          </li>
          <li>
            <strong>Google's LaMDA:</strong> A cutting-edge model designed for
            conversational AI.
          </li>
        </ul>

        <h3>The Game Changer: Llama 2</h3>
        <p>
          Meta's Llama 2 is an open-source AI model accessible to startups and
          researchers. Available in different sizes (7B, 13B, 70B-parameter
          models), it offers fine-tuning options.
        </p>
        <p>Key features:</p>
        <ul>
          <li>Accessibility and Versatility</li>
          <li>Innovation and Privacy (private hosting and customization)</li>
          <li>Performance Benchmarking (helpful responses for prompts)</li>
          <li>Cost and Community Benefits</li>
        </ul>

        <h3>Why the Distinction Matters:</h3>
        <p>
          Choose between open source and closed source LLMs based on your
          specific needs, resources, and goals.
        </p>
      </div>

      <div id="day8">
        <h2>Day 8 - Generative AI Applications and Use Cases</h2>
        <p>
          Let's explore the transformative applications of generative AI in
          business, examining how these technologies are reshaping various
          industries and enterprise functions.
        </p>

        <h3>Broad Spectrum of Business Applications:</h3>
        <ul>
          <li>
            <strong>Marketing and Advertising:</strong> From crafting compelling
            ad copy to generating creative landing pages, generative AI is
            revolutionizing how businesses approach marketing.
          </li>
          <li>
            <strong>Content Creation:</strong> AI now produces news articles and
            social media content, enhancing digital presence with minimal
            effort.
          </li>
          <li>
            <strong>Customer Service:</strong> AI-driven chatbots ensure
            engaging, natural conversations with customers, elevating the
            service experience.
          </li>
          <li>
            <strong>Summarization:</strong> Generative AI distills lengthy
            reports and papers into concise, informative summaries, aiding
            decision-making and research.
          </li>
          <li>
            <strong>Data Analysis:</strong> AI tools sift through vast datasets,
            uncovering patterns and insights that drive strategic decisions.
          </li>
          <li>
            <strong>Personalization:</strong> Tailoring content to individual
            user preferences or customer segments is more efficient with AI's
            generative capabilities.
          </li>
          <li>
            <strong>Product Development:</strong> Rapid prototyping and testing
            of new product designs are made possible, speeding up the innovation
            process.
          </li>
        </ul>

        <h3>Key Benefits for Businesses:</h3>
        <ul>
          <li>
            <strong>Increased Efficiency:</strong> Automate repetitive content
            generation tasks, freeing up valuable time for strategic work.
          </li>
          <li>
            <strong>Cost Savings:</strong> Reduce reliance on expensive human
            labor, particularly in creative and writing tasks.
          </li>
          <li>
            <strong>Consistency and Quality:</strong> Maintain a consistent
            brand voice while leveraging AI's analytical capabilities to produce
            high-quality content.
          </li>
          <li>
            <strong>Faster Ideation and Scalability:</strong> Accelerate the
            process of brainstorming and content production, enabling businesses
            to reach larger audiences more effectively.
          </li>
        </ul>

        <p>
          See my detailed list of Use Cases in this recent LinkedIn post. Here's
          the
          <a
            href="https://www.linkedin.com/posts/armand-ruiz_ai-is-not-hype-at-ibm-weve-completed-1000-activity-7130888264483295232-y9uc/?utm_source=share&utm_medium=member_desktop"
            >Link</a
          >
          .
        </p>

        <h3>Transforming Enterprise Operations:</h3>
        <p>
          Generative AI is not just a tool; it’s a game-changer for business
          operations. It enables businesses to scale creativity, streamline
          content creation, engage customers in novel ways, and achieve
          significant time and cost savings. The integration of AI into these
          functions is transforming how businesses interact with their
          customers, manage their internal processes, and innovate in their
          product offerings.
        </p>

        <p>
          Incorporating generative AI into business strategies can lead to more
          efficient, creative, and data-driven approaches, opening new avenues
          for growth and competitive advantage.
        </p>
      </div>

      <div id="day9">
        <h2>Day 9: The Generative AI Application Development Stack</h2>
        <p>
          Welcome to Day 9! Today, we're diving into the architecture of the
          Generative AI (GenAI) stack, crucial for crafting customized GenAI
          applications.
        </p>

        <h3>The GenAI Stack: A Modular, Integrated System</h3>
        <p>
          <strong>Understanding the GenAI Architecture:</strong> This system
          includes data pipelines, training and inference engines for LLMs,
          model registries, deployment monitoring, and user interfaces. Tools
          like LangChain offer orchestration layers for rapid transitions from
          data to models to apps.
        </p>

        <h4>Key Elements of the GenAI Stack:</h4>
        <ol>
          <li>
            <strong>Embeddings (Vectors):</strong> These transform
            high-dimensional data into lower-dimensional vectors, retaining
            essential information in a more manageable form.
          </li>
          <li>
            <strong>Vector Database:</strong> Stores and indexes vector
            representations for quick retrieval, supporting operations like
            vector search and similarity rankings, forming the backbone of
            vector infrastructure in AI.
          </li>
          <li>
            <strong>LangChain:</strong> An open-source framework built around
            LLMs, LangChain facilitates the design and development of various
            GenAI applications, including chatbots and Generative
            Question-Answering (GQA).
          </li>
          <li>
            <strong>LLMs and Prompts:</strong> The core of generative
            capabilities, LLMs respond to prompts to generate text, making them
            essential for applications like content creation and customer
            service.
          </li>
        </ol>

        <h3>Building a Simple GenAI App - Step-by-Step:</h3>
        <ol>
          <li>
            <strong>Load Document:</strong> Begin by loading the document or
            data source.
          </li>
          <li>
            <strong>Split into Chunks:</strong> Break the document into
            manageable parts.
          </li>
          <li>
            <strong>Create Embeddings:</strong> Convert these chunks into vector
            representations using embeddings.
          </li>
          <li>
            <strong>Store in Vector Database:</strong> Save these vectors in the
            database for efficient retrieval.
          </li>
          <li>
            <strong>User Interaction:</strong> Receive queries or input from the
            user and convert them into embeddings.
          </li>
          <li>
            <strong>Semantic Search in VectorDB:</strong> Connect to the vector
            database to perform a semantic search based on the user's query.
          </li>
          <li>
            <strong>Retrieve and Process Responses:</strong> Fetch relevant
            responses, pass them through an LLM, and generate an answer.
          </li>
          <li>
            <strong>Deliver Answer to User:</strong> Present the final output
            generated by the LLM back to the user.
          </li>
        </ol>

        <p>
          Understanding and utilizing the components of the GenAI stack is key
          for businesses looking to leverage AI for innovative applications.
          This modular approach allows for customization and scalability,
          fitting various business needs and goals.
        </p>
      </div>

      <div id="day10">
        <h2>Day 10: The Emergence of Small Language Models</h2>
        <p>
          On Day 10, we focus on the emerging trend of Small Language Models
          (SLMs) in the business world and their growing importance alongside
          Large Language Models (LLMs).
        </p>

        <h3>Understanding Large Language Models: A Refresher</h3>
        <p>
          <strong>Foundation of Today's NLP:</strong> LLMs, trained on vast text
          data, excel in generating coherent text and performing complex
          language tasks.
        </p>
        <p>
          <strong>Size and Complexity:</strong> Models like GPT-3 (175 billion
          parameters) and PaLM (540 billion parameters) represent the massive
          scale of LLMs, offering advanced capabilities but sometimes leading to
          challenges in accuracy and behavior.
        </p>
        <p><em>However, LLMs are very expensive:</em></p>
        <p>Running ChatGPT costs approximately $700,000 a day.</p>

        <h3>What are Small Language Models (SLMs)?</h3>
        <p>
          <strong>Defining SLMs:</strong> Generally defined as models with up to
          20 billion parameters, SLMs are tailored for specific business tasks
          like chat, analytics, and content generation.
        </p>
        <p>
          <strong>Agility and Customization:</strong> SLMs offer a balance of
          capability and control, making them well-suited for focused business
          applications.
        </p>

        <h4>Advantages of SLMs</h4>
        <p>
          <strong>Development and Risk Control:</strong> Easier to build and
          modify, SLMs reduce risks like bias and hallucinations due to simpler
          knowledge representations.
        </p>
        <p>
          <strong>Efficiency and Sustainability:</strong> Being lightweight and
          less computationally intensive, SLMs are ideal for deployment on
          smartphones and edge devices, contributing to sustainability.
        </p>
        <p>
          <strong>Cost-Effectiveness:</strong> SLMs offer significant cost
          savings, making AI more accessible for businesses.
        </p>
        <p>
          <em
            >"The speed of learning SLMs allow is huge, too. They're within the
            reach of so many more teams at lower cost. It just lets more
            innovation cycles happen faster." - Brad Edwards</em
          >
        </p>

        <h4>Benchmarking SLMs Against LLMs</h4>
        <p>
          <strong>Performance Comparisons:</strong> For instance, Mistral 7B
          outperforms larger models in certain benchmarks, demonstrating that
          SLMs can compete with or even surpass LLMs in specific tasks.
        </p>
        <p>
          <strong>Focused Training:</strong> SLMs like IBM Granite, despite
          smaller size and data, show competitive performance due to targeted
          training on industry-specific data.
        </p>

        <h4>Tuning Small Language Models</h4>
        <p>
          <strong>Customization Techniques:</strong> Similar to LLMs, SLMs can
          be fine-tuned using various methods to enhance performance for
          specific use cases.
        </p>
        <p>
          <strong>Example of Tuning:</strong> IBM’s Granite series, for
          instance, underwent specialized training for coding, showing how SLMs
          can be tailored to specific domains.
        </p>

        <h4>Use Cases of SLMs</h4>
        <p>
          <strong>Versatile Applications:</strong> SLMs are effective in text
          generation, chatbots, Q&A, and summarization, offering optimized
          solutions for resource-limited scenarios.
        </p>
        <p>
          <strong>Domain-Specific Tuning:</strong> SLMs can be trained for
          specialized fields like medical, legal, or technical translation,
          offering more accurate and relevant outputs than general-purpose LLMs.
        </p>

        <h3>In Summary</h3>
        <p>
          <strong>Balancing Capability and Practicality:</strong> SLMs are
          emerging as a practical alternative to LLMs in many business
          scenarios, offering a mix of specialized capabilities and control.
        </p>
        <p>
          SLMs represent a significant development in the AI landscape,
          providing businesses with more agile, cost-effective, and focused
          solutions for integrating AI into their operations.
        </p>
      </div>

      <div id="day11">
        <h2>Day 11: The AI Engineer Profession and Skills</h2>
        <p>
          Welcome to Day 11, where we explore the evolving and dynamic role of
          AI Engineers in the rapidly advancing field of Generative AI.
        </p>

        <h3>AI Engineering: A New Frontier</h3>
        <p>
          <strong>Role Definition:</strong> AI Engineers are the architects
          behind practical AI applications, handling everything from development
          to deployment of AI systems.
        </p>
        <p>
          <strong>Emerging Importance:</strong> As AI capabilities grow,
          particularly with the advent of Foundation Models, AI Engineers have
          transitioned from niche specialists to key players in tech and
          business landscapes.
        </p>
        <p>
          <em
            >"I believe the AI Engineer will be the highest-demand engineering
            job of the decade." - Anonymous</em
          >
        </p>

        <h4>Responsibilities of AI Engineers</h4>
        <ul>
          <li>
            <strong>AI Infrastructure:</strong> Develop and manage robust AI
            systems, ensuring scalability and efficiency.
          </li>
          <li>
            <strong>Advanced Prompting Strategies:</strong> Utilize tools like
            LangChain for sophisticated prompt engineering with LLMs.
          </li>
          <li>
            <strong>Data Management and Model Operations:</strong> Master data
            preprocessing and embedding techniques, and manage a diverse range
            of language models for varied applications.
          </li>
          <li>
            <strong>AI Model Integration:</strong> Transform AI models into
            accessible APIs for seamless integration with software systems.
          </li>
        </ul>

        <h3>Why AI Engineering is the Future</h3>
        <p>
          <strong>Demand and Recognition:</strong> With AI integration becoming
          crucial for businesses, AI Engineers are in high demand for their
          ability to turn AI advancements into practical solutions.
        </p>
        <p>
          <strong>Diverse Backgrounds:</strong> Professionals in this field are
          proving that diverse backgrounds can contribute significantly to AI
          product development, beyond traditional academic pathways.
        </p>

        <h4>The Path to Becoming an AI Engineer</h4>
        <ul>
          <li>
            <strong>Foundational Skills:</strong> Master programming (Python),
            machine learning, deep learning, and cloud computing.
          </li>
          <li>
            <strong>Recommended Courses:</strong> Consider enrolling in courses
            like the IBM AI Engineering Professional Certificate or
            DeepLearning.ai's specialized courses in AI and LLM application
            development.
          </li>
          <li>
            <strong>Portfolio Development:</strong> Build a portfolio showcasing
            your AI projects to demonstrate your skills to potential employers.
          </li>
        </ul>
        <p>
          Here's a good list of courses to start your AI Engineering journey:
          [link]
        </p>

        <h4>AI Engineer vs Data Scientist</h4>
        <p>
          <strong>Role Distinction:</strong> Data scientists focus on data
          analysis and model building, while AI Engineers specialize in building
          and deploying AI systems and infrastructure.
        </p>
        <p>
          <strong>Unique Contribution:</strong> AI Engineers are pivotal in
          implementing large-scale AI systems, like LLMs, in practical,
          operational environments.
        </p>

        <h3>The Future of AI Engineering</h3>
        <p>
          <strong>Market Trends:</strong> The demand for AI Engineers is
          expected to surpass that of data scientists as the field continues to
          evolve towards more complex, large-scale AI implementations.
        </p>
        <p>
          <strong>Shaping the AI Landscape:</strong> AI Engineers are key to
          crafting strategies and architectures that will define the future of
          digital innovation, making this role not just current but increasingly
          vital in the AI-driven future.
        </p>
        <p>
          AI Engineers stand at the forefront of the AI revolution, turning the
          promise of AI into tangible, valuable applications. This profession is
          not just about technical prowess; it's about shaping the future of how
          we interact with technology.
        </p>
        <p>
          <em>My prediction:</em> In numbers, there are probably going to be
          significantly more AI Engineers than there are data scientists.
        </p>
      </div>

      <div id="day12">
        <h2>Day 12 - Ethical Considerations in AI</h2>
        <p>
          As we approach the end of our AI series, Day 12 is dedicated to
          understanding the ethical considerations in AI, particularly the risks
          and responsibilities associated with deploying these powerful
          technologies.
        </p>
        <p><em>AI is the most powerful technology ever created.</em></p>

        <h3>Understanding the Risks of AI</h3>
        <ul>
          <li>
            <strong>Bias, Fairness, and Accuracy:</strong> AI systems can
            inadvertently replicate human biases present in training data,
            leading to unfair and inaccurate outcomes. Continuous improvement in
            data and training practices is crucial to enhance AI fairness.
          </li>
          <li>
            <strong>Job Disruption:</strong> AI's potential to automate tasks
            poses challenges for the job market, necessitating re-skilling
            initiatives and policy responses.
          </li>
          <li>
            <strong>Weaponization:</strong> The integration of AI into weapons
            systems raises ethical concerns about autonomy in warfare and the
            need for international governance.
          </li>
          <li>
            <strong>Cybersecurity Vulnerabilities:</strong> AI systems can be
            exploited for adversarial attacks, data poisoning, and model
            hacking, underscoring the importance of robust cybersecurity
            measures.
          </li>
          <li>
            <strong>Misinformation Spread:</strong> AI's ability to generate
            convincing fake news requires vigilance and tools to detect and
            mitigate the spread of misinformation.
          </li>
          <li>
            <strong>Emergence of AGI:</strong> The prospect of Artificial
            General Intelligence (AGI) adds another layer of ethical complexity,
            with implications for the future of humanity.
          </li>
        </ul>
        <p>
          <em
            >AI creating extinction risk for humanity is widely overhyped. AI
            develops gradually, and the “hard take off” scenario, where AI
            suddenly achieves superintelligence overnight is not realistic.</em
          >
        </p>

        <h3>The Role of AI Engineers in Mitigating Risks</h3>
        <ul>
          <li>
            <strong>Infrastructure Development:</strong> AI Engineers are
            responsible for developing and managing AI infrastructure, ensuring
            systems are robust, scalable, and secure.
          </li>
          <li>
            <strong>Ethical Implementation:</strong> Part of their role involves
            applying ethical AI practices, such as prompt engineering and data
            management, to minimize risks like bias and inaccuracy.
          </li>
          <li>
            <strong>Collaboration and Best Practices:</strong> AI Engineers must
            collaborate across functions to promote AI best practices and
            ethical standards within their organizations.
          </li>
        </ul>

        <h3>Mitigating Harmful AI Outputs</h3>
        <ul>
          <li>
            <strong>Hallucinations and Fabrications:</strong> AI systems can
            generate plausible but incorrect content. It's essential to design
            systems that minimize these risks.
          </li>
          <li>
            <strong>Data Poisoning and Toxic Language:</strong> AI must be
            safeguarded against harmful data inputs and language generation,
            requiring ongoing model training and content filtering.
          </li>
          <li>
            <strong>Unstable Task Performance:</strong> Addressing the
            inconsistent performance of AI models involves careful prompt
            engineering and verification processes.
          </li>
          <li>
            <strong>Human Oversight:</strong> Incorporating human review in
            high-stakes AI applications provides an additional layer of safety
            and accuracy.
          </li>
        </ul>

        <h3>The Path Forward: Ethical AI</h3>
        <ul>
          <li>
            <strong>Balancing Act:</strong> The challenge lies in leveraging
            AI's potential while responsibly managing its risks and ethical
            implications.
          </li>
          <li>
            <strong>Responsible Deployment:</strong> Implementing safety checks,
            transparency measures, and human oversight is crucial for ethical AI
            deployment.
          </li>
          <li>
            <strong>Ongoing Education and Policy Development:</strong>
            Continuous learning and policy evolution are necessary to keep pace
            with AI advancements and ensure its beneficial use.
          </li>
        </ul>
        <p>
          AI holds tremendous promise for transforming businesses and
          society.However, it's crucial to approach AI development and
          deployment with a keen awareness of its ethical implications, ensuring
          that these powerful tools are used responsibly and for the greater
          good.
        </p>
      </div>

      <div id="day13">
        <h2>Day 13 - Create Your AI for Business Roadmap</h2>
        <p>
          Welcome to Day 13 of our AI in 15 Days email course. Today, we cover
          how to plan AI in business by creating an effective AI Business
          Roadmap. As leaders in your respective fields, the strategic
          integration of AI can be a transformative step for your organization,
          driving efficiency, innovation, and substantial growth.
        </p>

        <h3>AI Business Roadmap: A Strategic Necessity</h3>
        <p>
          An AI Business Roadmap isn't just a technical layout; it's a
          comprehensive plan that aligns AI technologies with your specific
          business goals. This blueprint encompasses timelines, resources, and
          technical requirements, and addresses potential risks and human
          factors ensuring a smooth AI integration.
        </p>

        <h3>Creating Your Roadmap: A Step-by-Step Guide</h3>
        <ul>
          <li>
            <strong>Identify Business Objectives:</strong> Understand how AI can
            help achieve your goals, whether it's through automation, predictive
            analytics, AI chatbots, or innovative product development.
          </li>
          <li>
            <strong>Evaluate Data Infrastructure:</strong> AI needs quality
            data. Assess your data collection, storage, and cleanliness to
            ensure your AI initiatives can thrive.
          </li>
          <li>
            <strong>Assemble a Skilled Team:</strong> Combine business insight,
            technical skills, and data science. Include business strategists, AI
            specialists, and IT professionals, or seek external expertise as
            necessary.
          </li>
          <li>
            <strong>Choose Appropriate AI Technology:</strong> Select AI tools
            like ML, NLP, RPA, or Computer Vision, aligned with your business
            needs.
          </li>
          <li>
            <strong>Prototype Development:</strong> Start small with a pilot
            project to address specific challenges, refining AI models based on
            performance.
          </li>
          <li>
            <strong>Scale and Optimize:</strong> Expand successful prototypes,
            integrating them into broader business operations and continuously
            optimizing.
          </li>
          <li>
            <strong>Implement Change Management:</strong> Develop strategies to
            assist your workforce in adapting to AI, including training and
            understanding AI benefits.
          </li>
        </ul>

        <h3>High Impact, Low Effort AI Use Cases</h3>
        <p>
          Incorporate high-impact, low-effort AI applications such as AI
          chatbots for customer service, content generation, personalized
          marketing, predictive maintenance, routine task automation, fraud
          detection, demand forecasting, and streamlined recruitment. These use
          cases provide a strong foundation for your AI journey, ensuring
          meaningful returns with minimal initial effort.
        </p>
      </div>

      <div id="day14">
        <h2>Day 14 - Future Trends in AI</h2>
        <p>
          Welcome to Day 14 of our 15-day journey through the world of
          Generative AI. Today, we're venturing into the future to explore the
          exciting innovations we can expect in the next decade. Let's dive in!
        </p>

        <h3>Where Do We Come From?</h3>
        <p>
          Understanding AI's journey is key to predicting its future. The past
          decade laid the foundation for advancements in machine learning and
          neural networks. Now, we're poised to build on this legacy, driving AI
          towards more sophisticated and nuanced applications.
        </p>
        <p>
          In traditional machine learning, individual siloed models require
          task-specific training and a significant amount of human-supervised
          learning. The limit on performance and capabilities for supervised
          learning lies with humans.
        </p>
        <p>
          In contrast, foundation models are massive multi-tasking systems,
          adaptable with little or no additional training, utilizing
          pre-trained, self-supervised learning techniques. The limit on
          performance and capabilities is mostly related to computing power and
          data access (not labeling).
        </p>

        <h3>Synthetic Data</h3>
        <p>
          If the limit to a better model is more data, why not create it
          artificially? The rise of synthetic data is a game-changer. It
          involves creating artificial datasets that can train AI without
          compromising privacy or relying on scarce real-world data. This
          innovation is set to revolutionize fields from healthcare to
          autonomous driving, making AI training more accessible, ethical, and
          comprehensive.
        </p>
        <p>
          We will see increased usage of synthetic data because it overcomes
          data scarcity by allowing limitless generation, ensures balanced data
          distribution to avoid biases, and is cost-effective, bypassing the
          expensive and time-consuming process of real-world data collection and
          labeling.
        </p>

        <h3>Multimodality</h3>
        <p>
          Multimodality is the future of AI's interaction with the world. By
          integrating text, image, sound, and more, AI can understand and
          respond to complex queries with unprecedented accuracy. This holistic
          approach will deepen AI's integration into daily life, from smarter
          virtual assistants to more intuitive educational tools.
        </p>

        <h3>Reinforcement Learning</h3>
        <p>
          Want to take it to the next level? What if you could train AI without
          data? Meet Reinforcement Learning, a technique poised to make
          significant strides. By learning through trial and error, AI systems
          will become more autonomous and capable of solving complex, real-world
          problems. This means smarter algorithms in everything from financial
          forecasting to climate change modeling.
        </p>
        <p>
  Check out <a href="https://youtu.be/kopoLzvh5jY?si=fxZR5632WMuAC69p">this video</a> to see a demonstration of Reinforcement Learning in action:
</p>

        <h3>Giving Tools to AI</h3>
        <p>
          In the next decade, AI will evolve beyond being just a tool to
          becoming a creator of tools. We will see AI designing software,
          crafting algorithms, and contributing to AI research. AI agents will
          autonomously manage projects in a continuous loop, executing tasks,
          enhancing results, and generating new tasks based on objectives and
          past outcomes. Their workflow will include task execution, result
          enrichment, task creation, and prioritization. Equipped with
          integration capabilities, these agents will be able to search for
          information in CRMs, access databases, send emails, and more.
          Frameworks like BabyAGI and Auto-GPT are already emerging to test
          these concepts.
        </p>

        <h3>Beyond Chats</h3>
        <p>
          While chatbots and conversational AI have made leaps, the future
          extends far beyond text. Expect AI that can seamlessly interact across
          various formats, offering richer, more immersive experiences. Whether
          it's in education, entertainment, or customer service, AI will engage
          us in more meaningful, dynamic ways.
        </p>
      </div>

      <div id="day15">
        <h2>Day 15 - Continuing Your AI Journey</h2>
        <p>Welcome to Day 15 of our 15-day exploration into Generative AI. Today, we're not at the end, but rather at the beginning of a lifelong journey in AI learning and exploration. Let's discuss how you can continue growing in this exciting field:</p>
    
        <h3>Online Courses & Tutorials</h3>
        <p>I've created the AI Bootcamp, which provides the next level of practice. It includes videos and exercises with multiple tools, and the best part is that no coding knowledge is required. Get your free access <a href="https://www.nocode.ai/the-ai-bootcamp/" class="link" target="_blank">here</a>.</p>
        <p>If you're ready for deeper insights, I recommend exploring the Short Courses from DeepLearning.ai. These courses cover topics such as:</p>
        <ul>
            <li><a href="https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Functions, Tools, and Agents with LangChain</a></li>
            <li><a href="https://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Vector Databases: from Embeddings to Applications</a></li>
            <li><a href="https://www.deeplearning.ai/short-courses/quality-safety-llm-applications/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Quality and Safety for LLM Applications</a></li>
            <li><a href="https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Building and Evaluating Advanced RAG Applications</a></li>
            <li><a href="https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Reinforcement Learning from Human Feedback</a></li>
        </ul>
        <p>These courses assume basic Python knowledge.</p>
    
        <h3>Follow Leaders in the AI Space</h3>
        <p>Stay connected by following AI leaders on LinkedIn:</p>
        <ul>
            <li><a href="https://www.linkedin.com/in/aishwarya-srinivasan/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Aishwarya Srinivasan</a>: Data Scientist | LinkedIn Top Voice Data & AI | EB1A Recipient | 460k+ Followers | Formerly at Google and IBM</li>
            <li><a href="https://www.linkedin.com/in/alliekmiller/" class="link">Allie K. Miller</a>: AI Entrepreneur, Advisor, and Investor | 1MM+ followers | Formerly at Amazon and IBM | LinkedIn Top Voice for AI 2019-2023</li>
            <li><a href="https://www.linkedin.com/in/luisgserrano/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Luis Serrano</a>: AI Scientist | YouTuber with 120K followers | Author of "Grokking Machine Learning"</li>
            <li><a href="https://www.linkedin.com/in/andriyburkov/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">Andriy Burkov</a>: ML at TalentNeuron | Author of "The Hundred-Page Machine Learning Book" and "Machine Learning Engineering"</li>
        </ul>
        <p>Additionally, I publish daily content with practical tips and best practices for applying AI in business. Feel free to follow me <a href="https://www.linkedin.com/in/armand-ruiz/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">here</a>.</p>
    
        <h3>Join Newsletters</h3>
        <p>Stay informed by subscribing to newsletters that summarize daily AI news. These will keep you up-to-date on the latest trends and tools:</p>
        <ul>
            <li><a href="https://www.therundown.ai/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">The Rundown</a></li>
            <li><a href="https://www.bensbites.com/" class="link">Ben's Bites</a></li>
            <li><a href="https://www.theneurondaily.com/?utm_source=newsletter.nocode.ai&utm_medium=newsletter&utm_campaign=day-15-continuing-your-ai-journey" class="link">The Neuron</a></li>
        </ul>
    
        <p>Remember, the field of AI is ever-evolving, and continuous learning is essential. Embrace curiosity, keep experimenting, and stay connected with the AI community. You're now equipped to take the next steps in your AI journey.</p>
    </div>
    <footer>
      <div class="footer-content">
          <p class="motto">Transforming Ideas with AI</p>
          <p class="author-name">Santhosh D</p>
          <div class="social-links">
              <a href="https://www.linkedin.com/in/santhosh-d-a58b69200?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app " target="_blank"><img src="https://img.icons8.com/?size=100&id=xuvGCOXi8Wyg&format=png&color=000000" alt="linkedin" width="30" height="30">
              </a>
              <a href="https://github.com/SanthoshD123" target="_blank"><img src="https://img.icons8.com/?size=100&id=wqGmdISvpm0c&format=png&color=000000" alt="GitHub" width="30" height="30">
              </a>
          </div>
      </div>
  </footer>
    
    

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const dayButtons = document.querySelectorAll(".day-button");
        const dayContents = document.querySelectorAll(".content > div");

        function showDay(dayNumber) {
          dayContents.forEach((content) => content.classList.remove("active"));
          const selectedDay = document.getElementById(`day${dayNumber}`);
          if (selectedDay) {
            selectedDay.classList.add("active");
          }
        }

        dayButtons.forEach((button) => {
          button.addEventListener("click", function () {
            const day = this.getAttribute("data-day");
            showDay(day);
          });
        });

        // Show Day 1 by default
        showDay(1);
      });
    </script>       
      
  </body>
</html>
